+++
title = 'About'
# date = 2024-03-11T17:27:04+05:30
draft = false
weight = 101
+++

I possess experience in comprehending the functioning of Transformer models and accelerating these LLM models using futuristic technology namely In-Memory Computing. Additionally, I have hands-on expertise in enhancing the efficiency of the BERT model for a correspondence classification task. 

In addition to my passion for all things beyond Earth, my interests encompass machine learning algorithms, programming, and an insatiable curiosity to understand the underlying "why" and "what" behind a wide spectrum of subjects.